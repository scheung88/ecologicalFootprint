---
title: "Net Ecological Footprint of Countries in the World"
author: "Shirley Cheung and Tuan Nguyen"
date: "April 30, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) 
```

# Introduction
A third of all food produced for human consumption --- 1.3 billions tons --- is wasted every year. This amounts to an annual global loss of \$990 billion, of which the United States alone contributes \$165 billion ([FAO](http://www.fao.org/save-food/resources/keyfindings/en/)). This is a devastating waste of resources: from the food itself to the labor, time, and additional capital required to produce this food (ie. water). In a world where there still exist countries that suffer from hunger and global population which grows exponentially, we simply can't afford to misuse our resources in this imprudent manner. 

To estimate the entirety of wasted resources and not just food alone, we can use two existing metrics: ecological footprint and biocapacity. Intuitively, ecological footprint is the "amount of nature" required to sustain a given population. This figure might include the amount of land needed to absorb carbon dioxide emissions or the amount of land necessary to grow enough food to feed a population. Biocapacity is the "amount of nature" actually available for consumption needs. For instance, the biocapacity of land accessible for food production might be 1000 hectares in one country, but only 500 hectares in another. A familiar analogy of biocapacity and ecological footprint is supply and demand (respectively), where we're now simply dealing in units of biologically productive land. A country runs an ecological deficit when its footprint exceeds its biocapacity and an ecological surplus when its biocapcity exceeds its footprint. Henceforth, we will simply refer to the ecological deficit/surplus of a nation as its net footprint. 

In this project, we build two multilevel models --- linear and logistic --- to explore, on a country level, the relationship between net footprint and the following variables: 

* Population
* GDP per capita
* Total food production
* Greenhouse gas emission
* Human Development Index
* Continent 

Data on net footprint, population, and GDP per capita was collected from the Global Footprint Network and downloaded from [Kaggle](https://www.kaggle.com/footprintnetwork/ecological-footprint). These variables were recorded for the year 2016. The variable of total food production was created using data from the Food and Agriculture Organization of the United Nations (FAO) and also downloaded from [Kaggle](https://www.kaggle.com/unitednations/global-food-agriculture-statistics/data). Unfortunately, data for 2016 was not available; thus, we used the most recent data of 2013. The variable of greenhouse gas emission was collected from the [World Resources Institute](http://www.wri.org/resources/data-sets/cait-country-greenhouse-gas-emissions-data). Similar to the food production data, the year 2016 was not available and thus we used the most recent year of 2012. Finally, data on the 2015 Human Development Index was collected from the [United Nations Development Programme](http://hdr.undp.org/en/data#). The Human Development Index measures the cultural and social "strength" of a population such as the average life span, level of education, and standard of life. To summarise, 

Variable                  | Type  |  Year  | Source
------------------------- | ----- | ------ | ----------
Net Footprint             |  $y$  |  2016  | [Global Footprint Network](https://www.kaggle.com/footprintnetwork/ecological-footprint)
Population                |  $x$  |  2016  | [Global Footprint Network](https://www.kaggle.com/footprintnetwork/ecological-footprint)
GDP per capita            |  $x$  |  2016  | [Global Footprint Network](https://www.kaggle.com/footprintnetwork/ecological-footprint)
Continent                 |  $x$  |  2016  | [Global Footprint Network](https://www.kaggle.com/footprintnetwork/ecological-footprint)
Total food production     |  $x$  |  2013  | [Food and Agriculture Organization](https://www.kaggle.com/unitednations/global-food-agriculture-statistics/data)
Greenhouse gas emission   |  $x$  |  2012  | [World Resources Institute](http://www.wri.org/resources/data-sets/cait-country-greenhouse-gas-emissions-data)
Human development index   |  $x$  |  2015  | [United Nations Development Programme](http://hdr.undp.org/en/data#)


# Wrangling
Because the data on our predictors originated from various sources, the majority of wrangling efforts were spent reconciling differences in naming conventions between datasets, then joining the two datasets. We will explore this in further detail in the following sections. 

### Libraries
First, let's load the packages we need for wrangling:

```{r, message = FALSE, warning = FALSE}
library(readr)
library(dplyr)
library(tidyr)
library(ggmap)
library(maps)
``` 

### Ecological Data
Our first dataset is the ecological data downloaded from the Global Footprint Network on [Kaggle](https://www.kaggle.com/footprintnetwork/ecological-footprint). This data contains our $y$ variable of interest, net ecological footprint, as well as two predictor variables: population and GDP per capita. In the code below, we read in our ecological data, adjust variable names, and clean up our `GDPperCapita` variable so that it does not contain commas and dollar signs. Moving forward, we use this dataset as a "base" to which we add additional predictor variables.

```{r, message = FALSE, warning = FALSE, eval = FALSE}
# Reading in eco dataset
ecoData <- read_csv("countries.csv") 
names(ecoData) <- gsub(" ", "", names(ecoData )) 

# Cleaning up eco dataset
ecoData  <- ecoData  %>%
  rename("country" = "Country", 
         "region" = "Region",
         "population" = "Population(millions)",
         "totalFootprint" = "TotalEcologicalFootprint",
         "totalBiocap" = "TotalBiocapacity",
         "netFootprint" = "BiocapacityDeficitorReserve") %>%
  dplyr::select(country, region, population, GDPperCapita, netFootprint) %>%
  mutate(GDPperCapita = 
           str_replace_all(GDPperCapita, 
                           c("[:punct:]" = "", "\\$" = ""))) %>%
  mutate(GDPperCapita = as.numeric(GDPperCapita))
```

### Adding World Data
Eventually, we want to create chloropleth maps of net ecological footprint by country. To do this, we must add the world dataset from the `maps` package to our existing data. The world dataset contains a list of all countries in the world, as well as their geographical locations. But before we can join our two datasets, we first need to check for differences in naming conventions. It's unfortunate if our datasets don't join entirely due to missing observations in one dataset, but it's lazy data science if our datasets don't join entirely due to spelling oversight! 

To check for spelling differences, we can simply antijoin our two datasets. Antijoining our ecological data with the world data provides us with all countries observed in our ecological data that were not observed in the world data. We can then go through each of the countries listed in the antijoin and compare it with the world data to check if the observation is truly missing or if it's simply a spelling difference. 

In the code snippet below, you might notice that we've recoded country names in both datasets. Why not just recode the country names in the ecological dataset alone? Of course that's a valid option, but this choice actually doesn't make sense in our case. For example, in our world dataset, we've combined the two entities of `Antigua` and `Barbuda` into one entity of `Antigua and Barbuda`. This is because our ecological data (as well as all other predictor datasets) only have observations for the *joint* entity `Antigua and Barbuda`. If we were to perform all recoding in the ecological dataset alone, we'd have to split our observation of `Antigua and Barbuda` into two --- how would you split the observation? An even split? A proportional split by the size of each region? It's safe to say that the wiser choice is simply to combine Antigua and Barbuda in our world dataset since we're just changing the labels on geographical locations. 

```{r, message = FALSE, warning = FALSE, eval = FALSE}
# Reading in world dataset
world <- map_data("world") %>%
  dplyr::select(-subregion) 

# Finding countries in common that won't join because of spelling
spellingErrors <- anti_join(ecoData, world, by = c("country" = "region"))

# Fixing world names
world <- world %>%
  mutate(region = recode(region, 
                         "Antigua" = "Antigua and Barbuda",
                         "Barbuda" = "Antigua and Barbuda",
                         "Virgin Islands" = "British Virgin Islands",
                         "Brunei" = "Brunei Darussalam",
                         "Saint Kitts" = "Saint Kitts and Nevis",
                         "Saint Vincent" = "Saint Vincent and Grenadines",
                         "Trinidad" = "Trinidad and Tobago",
                         "Tobago" = "Trinidad and Tobago",
                         "UK" = "United Kingdom",
                         "USA" = "United States of America",
                         "Wallis and Futuna" = "Wallis and Futuna Islands"))

# Fixing eco names
ecoData <- ecoData %>%
  mutate(country = recode(country,
                          "Cabo Verde" = "Cape Verde",
                          "Congo" = "Republic of Congo",
                          "Congo, Democratic Republic of" = 
                            "Democratic Republic of the Congo",
                          "CÃ´te d'Ivoire" = "Ivory Coast",
                          "Iran, Islamic Republic of" = "Iran",
                          "Korea, Democratic People's Republic of" =
                            "South Korea",
                          "Korea, Republic of" = "North Korea",
                          "Lao People's Democratic Republic" = "Laos",
                          "Libyan Arab Jamahiriya" = "Libya",
                          "Macedonia TFYR" = "Macedonia",
                          "RÃ©union" = "Reunion",
                          "Russian Federation" = "Russia",
                          "Syrian Arab Republic" = "Russia",
                          "Tanzania, United Republic of" = "Tanzania",
                          "Venezuela, Bolivarian Republic of" =
                            "Venezuela",
                          "Viet Nam" = "Vietnam"))

# Merging eco and world data
ecoData <- ecoData %>%
  left_join(world, by = c("country" = "region")) %>%
  dplyr::select(-region)
```

### Adding Total Food Production Data
For our production data, the framework of wrangling remains largely the same: reading in the production data, antijoining for spelling differences, then joining with our ecological data. There are, however, several additional steps different from prior wrangling. First, we calculate total food production by summing production across food categories (ie. grains, fruits and vegetables, meat). Second, our antijoin tells us that our production data has three versions of China: `China, Hong Kong SAR`, `China, Macao SAR`, and `China, mainland`. Simply recoding these three versions of China into `China` does not sum their respective food production values. In this case, we must first isolate our three observations of China from the production data, recode and sum our observations before adding our new `China` observation back to the production data. 

```{r, message = FALSE, warning = FALSE, eval = FALSE}
# Reading in production data and calculating total food production
production <- read_csv("production.csv") %>%
  replace_na(list(region = "NA")) %>% # NA's = North America
  group_by(Area, Year) %>% 
  mutate(totalProduction = as.numeric(sum(Production))) %>%
  filter(Year == 2013) %>%
  ungroup() %>%
  distinct(Area, .keep_all = TRUE) %>%
  dplyr::select(region, Area, totalProduction) %>%
  rename("continent" = "region", "country" = "Area")

# Finding countries in common with eco Data that won't join because of spelling
spellingErrors <- anti_join(production, ecoData, by = "country")

## Combining China's total production
china <- production %>%
  filter(country %in% c("China, Hong Kong SAR", 
                        "China, Macao SAR",
                        "China, mainland")) %>%
  mutate(country = recode(country, 
                          "China, Hong Kong SAR" = "China",
                          "China, Macao SAR" = "China",
                          "China, mainland" = "China")) %>%
  group_by(continent, country) %>%
  summarise(totalProduction = sum(totalProduction))

## Updating production data
production <- production %>%
  filter(!(country %in% c("China, Hong Kong SAR", 
                        "China, Macao SAR",
                        "China, mainland"))) %>%
  full_join(china)

# Fixing names in production data
production <- production %>%
  mutate(country = recode(country,
                          "Bolivia (Plurinational State of)" = "Bolivia",
                          "Cabo Verde" = "Cape Verde",
                          "Congo" = "Republic of Congo",
                          "Czechia" = "Czech Republic",
                          "Democratic People's Republic of Korea" =
                            "South Korea",
                          "Iran (Islamic Republic of)" = "Iran",
                          "Lao People's Democratic Republic" = "Laos",
                          "Republic of Korea" = "North Korea",
                          "Republic of Moldova" = "Moldova",
                          "Saint Vincent and the Grenadines" =
                            "Saint Vincent and Grenadines",
                          "Russian Federation" = "Russia",
                          "The former Yugoslav Republic of Macedonia" =
                            "Macedonia",
                          "United Republic of Tanzania" = "Tanzania",
                          "Venezuela (Bolivarian Republic of)" = 
                            "Venezuela",
                          "Viet Nam" = "Vietnam"))

# Merging eco and production data 
ecoData <- ecoData %>%
  left_join(production, by = "country")
```

### Adding Greenhouse Gas Data
Adding our data on greenhouse gas emissions is extremely straight forward. We read in our dataset, check and fix spelling differences, then join with our ecological dataset. Very simple compared to the wrangling of our production data!

```{r, message = FALSE, warning = FALSE, eval = FALSE}
# Reading in greenhouse gas dataset
greenhouse <- read_csv("CAITGHGData.csv") %>% 
  filter(Year == 2012) %>%
  rename("totalGHG" = `Total GHG Emissions Including Land-Use Change and Forestry (MtCO?e?)`) %>%
  dplyr::select(Country, totalGHG)
  
# Finding countries in common that won't join because of spelling
spellingErrors <- anti_join(greenhouse, ecoData, by = c("Country" = "country"))

# Fixing names and merging with production data
## Some countries are missing in eco data so there's nothing we can do about
## missing observations
greenhouse <- greenhouse %>%
  mutate(Country = recode(Country,
                          "Antigua & Barbuda" = "Antigua and Barbuda",
                          "Bahamas, The" = "Bahamas",
                          "Bosnia & Herzegovina" = "Bosnia and Herzegovina",
                          "Brunei" = "Brunei Darussalam",
                          "Congo, Dem. Rep." = 
                            "Democratic Republic of the Congo",
                          "Congo, Rep." = "Republic of Congo",
                          "Cote d'Ivoire" = "Ivory Coast",
                          "Korea, Rep. (South)" = "South Korea",
                          "Korea, Dem. Rep. (North)" = "North Korea",
                          "Macedonia, FYR" = "Macedonia",
                          "Russian Federation" = "Russia",
                          "Saint Kitts & Nevis" = "Saint Kitts and Nevis",
                          "Saint Vincent & Grenadines" = 
                            "Saint Vincent and Grenadines",
                          "Trinidad & Tobago" = "Trinidad and Tobago",
                          "United States" = "United States of America",
                          "United States of America" = "USA"))

# Merging greenhouse gas dataset with eco dataset
ecoData <- ecoData %>%
  left_join(greenhouse, by = c("country" = "Country"))
```

### Adding HDI Data
Similar to the wrangling of our greenhouse gas data, the wrangling of our Human Development Index data is equally straight forward. At this point, we have finished adding all predictors to our dataset. Note that in the last two lines of the following code snippet, we create two new forms of our $y$ variable, net footprint. The first transformation, `binomFootprint`, is a categorical variable which takes on the value of 0 when our net footprint is negative and the value of 1 when our net footprint is greater than or equal to 0. The second transformation, `transFootprint`, retains the quantitative aspect of net footprint by adding 15 and taking the log of this sum. The justification for this transformation will be justified in the following section. 

```{r, message = FALSE, warning = FALSE, eval = FALSE}
# Reading in HDI data
HDI <- read_csv("HDI.csv") %>% 
  rename("country" = "Country",
         "HDI2015" = `2015`) %>%
  dplyr::select(country, HDI2015)

# Finding countries in common that won't join because of spelling
spellingErrors <- anti_join(HDI, ecoData, by = "country")

# Fixing spelling errors
HDI <- HDI %>%
  mutate(country = recode(country,
         "Bolivia (Plurinational State of)" = "Bolivia",
         "Cabo Verde" = "Cape Verde",
         "Congo" = "Republic of Congo",
         "Congo (Democratic Republic of the)" = 
           "Democratic Republic of the Congo",
         "C<99>te d'Ivoire" = "Ivory Coast",
         "Iran (Islamic Republic of)" = "Iran", 
         "Korea (Republic of)" = "North Korea",
         "Lao People's Democratic Republic" = "Laos",
         "Moldova (Republic of)" = "Moldova",
         "Russian Federation" = "Russia",
         "Saint Vincent and the Grenadines" = 
           "Saint Vincent and Grenadines", 
         "Tanzania (United Republic of)" = "Tanzania",
         "The former Yugoslav Republic of Macedonia" = "Macedonia",
         "United States" = "United States of America",
         "Venezuela (Bolivarian Republic of)" = "Venezuela",
         "Viet Nam" = "Vietnam"))
HDI$country[HDI$HDI2015 == 0.474] <- "Ivory Coast"

# Merging with HDI data
ecoData <- ecoData %>%
  left_join(HDI, by = "country") %>%
  drop_na() %>%
  mutate(binomFootprint = as.factor(ifelse(netFootprint < 0, 0, 1))) %>%
  mutate(transFootprint = log(netFootprint + 15))
```

Now that we're done with wrangling, let's save our work! Since this was a significant amount of wrangling, if we save our final datasets, we wouldn't have to run our code again every time we revisited this blog. 

```{r, eval = FALSE}
# Ecological data without world map data
## This form of data is better for building our models because the original
## form is too large and slows down the machine
ecoDataReg <- ecoData %>%
  distinct(country, .keep_all = TRUE) %>%
  dplyr::select(-lat, -long, -group, -order)

# Saving our final eco datasets
write_csv(ecoData, "ecoData.csv") 
write_csv(ecoDataReg, "ecoDataReg.csv")
```


# Model Assumptions of Linear Regression
If you remember from the introduction, we're going to build a linear multilevel model and a logistic multilevel model. But before we can build our linear model, it's crucial that we first check we haven't violated any assumptions of linear regression. First, let's take a look at our $y$ variable, net footprint. 

```{r, message = FALSE, warning = FALSE, echo = FALSE} 
# Reading in already finalized datasets so we don't have to run
# wrangling code every time we knit
ecoData <- read_csv("ecoData.csv") 
ecoDataReg <- read_csv("ecoDataReg.csv")  

netFootprint <- ecoDataReg$netFootprint
transFootprint <- ecoDataReg$transFootprint
binomFootprint <- ecoDataReg$binomFootprint
population <- ecoDataReg$population
totalProduction <- ecoDataReg$totalProduction 
GDPperCapita <- ecoDataReg$GDPperCapita 
totalGHG <- ecoDataReg$totalGHG  
HDI2015 <- ecoDataReg$HDI2015 
```

```{r}
library(ggplot2)

# Frequency of Net Footprint
ggplot(data = ecoDataReg, aes(x = netFootprint)) +
  geom_histogram(binwidth = 1, fill = "#cd8c95", color = "white") +
  labs(title = "Histogram of Net Footprint", x = "Net Footprint",
       y = "Frequency") +
  theme_minimal()

# Range of Net Footprint values 
range(netFootprint)
```

From our histogram, it seems that net footprint is pretty normally distributed, but there are several extreme outliers. Using `range()` on net footprint tells us that our values lie betwen between -14.14 and 85.08. We can "pull" in our outliers by taking a log transformation our variable. But because we can't take the log of a negative number, we first shift our distribution up by 15 units. Thus, our transformed net footprint variable becomes: $$\text{transFootprint} = \text{log}(\text{netFootprint} + 15)$$

Now let's take a look at the histogram of our transformed net footprint variable:
```{r}
# Frequency of Transformed Net Footprint
ggplot(data = ecoDataReg, aes(x = log(netFootprint + 15))) +
  geom_histogram(binwidth = 0.1, fill = "#cd8c95", color = "white") +
  labs(title = "Histogram of Transformed Net Footprint", 
       x = "Transformed Net Footprint",
       y = "Frequency") +
  theme_minimal()

# Range of Transformed Net Footprint Values
range(log(netFootprint + 15))
```

From this histogram, we see that although outliers still exist, our log transformation pulled in our previously very extreme outliers. And our transformed net footprint still seems normally distributed! 

Now let's check to see if our transformed net footprint variable and our predictor variables have linear relationships. Let's first take a look at population. Below is a scatterplot of population plotted against our transformed net footprint. 

```{r}
# Untransformed X
ggplot(data = ecoDataReg, aes(x = population, y = transFootprint)) +
  geom_point(color = "#7289DA", alpha = 0.5) +
  labs(title = "Transformed Net Footprint vs. Population",
       x = "Population (millions)", 
       y = "Transformed Net Footprint") +
  theme_minimal()
```

Hmm... Definitely not a linear relationship. Let's try to fix this by taking a log transformation of population since we took a log transformation of net footprint. 

```{r}
# Transformed X
ggplot(data = ecoDataReg, aes(x = log(population), y = transFootprint)) +
  geom_point(color = "#7289DA", alpha = 0.5) +
  labs(title = "Transformed Net Footprint vs. Transformed Population",
       x = "Transformed Population", 
       y = "Transformed Net Footprint") +
  theme_minimal()
```

We see that taking a log transformation of population seems to remedy the  non-linear relationship between transformed net footprint and transformed population. In fact, after checking the relationships between our transformed $y$ variable and all of our predictors, we end up taking a log transformation of all predictors, as shown below:

```{r}
# GDP per Capita
ggplot(data = ecoDataReg, aes(x = log(GDPperCapita), y = transFootprint)) +
  geom_point(color = "#7289DA", alpha = 0.5) +
  labs(title = "Transformed Net Footprint vs. Transformed GDP per Capita",
       x = "Transformed GDP per Capita", 
       y = "Transformed Net Footprint") +
  theme_minimal()

# Total Food Production
ggplot(data = ecoDataReg, aes(x = log(totalProduction), y = transFootprint)) +
  geom_point(color = "#7289DA", alpha = 0.5) +
  labs(title = "Transformed Net Footprint vs. Transformed Total Food Production",
       x = "Transformed Total Food Production", 
       y = "Transformed Net Footprint") +
  theme_minimal()

# Greenhouse Gas Emissions
ggplot(data = ecoDataReg, aes(x = log(totalGHG), y = transFootprint)) +
  geom_point(color = "#7289DA", alpha = 0.5) +
  labs(title = "Transformed Net Footprint vs. Transformed Total GHG Emissions",
       x = "Transformed Total GHG Emissions", 
       y = "Transformed Net Footprint") +
  theme_minimal()

# Human Development Index
ggplot(data = ecoDataReg, aes(x = log(HDI2015), y = transFootprint)) +
  geom_point(color = "#7289DA", alpha = 0.5) +
  labs(title = "Transformed Net Footprint vs. Transformed HDI",
       x = "Transformed HDI", 
       y = "Transformed Net Footprint") +
  theme_minimal()
```

Thus, our linear regression becomes $$\text{log}(y_{i} + 15) = \beta_{0} + \beta_{1}log(x_{i1}) + \beta_{2}log(x_{i2}) + \beta_{3}log(x_{i3}) + \beta_{4}log(x_{i4}) + \beta_{5}log(x_{i5})$$ where
+ $y_i$ denotes the $i^{th}$ observation of net footprint
+ $x_{i1}$ denotes the $i^{th}$ observation of population
+ $x_{i2}$ denotes the $i^{th}$ observation of GDP per capita
+ $x_{i3}$ denotes the $i^{th}$ observation of total food production
+ $x_{i4}$ denotes the $i^{th}$ observation of greenhouse gas emission
+ $x_{i5}$ denotes the $i^{th}$ observation of the human development index. 

It is important to note that while we have a linear relationship between our transformed $x$'s and $y$, the relationship between our original $x$'s and $y$ is multiplicative.

Now let's check the residual and QQ plots of our regression model. We first build our model using the `lm()` command and call it `fit1`. In base R, you can create residual and QQ plots by using `plot(fit1)`. To create these plots in `ggplot`, we can use the `autoplot()` function from the `ggfortify` library. 

```{r, warning = FALSE, message = FALSE}
library(ggfortify)

# Regression 
fit1 <- lm(transFootprint ~ log(population) + log(totalProduction) +
             log(GDPperCapita) + log(totalGHG) + log(HDI2015), 
           data = ecoDataReg)

# Residual Plot
autoplot(fit1, which = 1, ncol = 1) +
  theme_minimal()

# Normal QQ Plot
autoplot(fit1, which = 2, ncol = 1) +
  theme_minimal()
```

Our residual plot seems to be in good shape --- there's even spread and constant variance. There are a few outliers, but we don't observe any pattern in our residuals. While our Normal QQ plot isn't perfect, we see that our points mostly fall on the $y=x$ dotted line, with the exception of the tails. Taking into account all assumptions we tested in this section, it's safe to say we can proceed with building our model!

# Hierarchical Models
Hierarchical models are in fact quite intuitive. For example, if you have data on students in classrooms and schools, you have a two-level hierarchy: classrooms within schools. If you also have data on school districts, then you have a three-level hierarchy: classrooms within schools within school districts. In this case, we have have a two-level hierarchy: countries within continents. Hierarchical models are also called multilevel models (depending on whether you're a Frequentist or a Bayesian and have prior information). To fit hierarchical models in R, the `lme4` package is your best bet.

### Normal Hierarchical Model
Our first hierarchical model is a normal hierarchical model. We call it "normal" because it uses transFootprint as our $y$ variable, which we've assumed to be normally distributed after checking our model assumptions in the prior section. You might notice that our regression code tested below is almost identical to the one we already wrote earlier, `fit1`. The only difference is the added measure of continent. Writing continent as (1|continent) adds the multi-level element to our model and tells R that we wish to add continent to our model as a random effect, rather than a fixed one. Using continent as a random effect hypothesizes that our net footprint will vary by continent. 

```{r, warning = FALSE, message = FALSE, cache = TRUE}
library(lme4)

normalModel <- lmer(transFootprint ~ (1|continent) + 
                       log(population) + 
                       log(totalProduction) +
                       log(GDPperCapita) + 
                       log(totalGHG) + log(HDI2015), 
                     data = ecoDataReg)

summary(normalModel)
```

In the summary output of our normal hierarchical model, we see that the variance of continent is 0.04471, which is quite small. This suggests that adding continent to our model not as helpful as we would have hoped. In addition, all of our predictors, except for `GDPperCapita`, are insignificant. GDP seems to have a negative correlation with net footprint. One hypothesis as to why this may be true is that richer countries may import more goods from other countries and therefore be less taxing their own natural resources. (Note: we're using these terms very loosely. In reality we're talking about the log(GDP) and log(net footprint + 15), as we derived earlier).

### Binomial Hierarchical Model
Our second hierarchial model is a binomial hierarchical model. In this case, we've mutated our original $y$ variable of net footprint into `binomFootprint`, which consists of 1's and 0's -- 1 if the country has an ecologicial surplus and 0 if the country has a ecological deficit. Thus `binomFootprint` is binomially distributed and we call this model "binomial." We can also remove our log transformations since they were only necessary in our normal model.

```{r, warning = FALSE, message = FALSE, cache = TRUE}
binomialModel <- glmer(binomFootprint ~ (1|continent) + 
                       population + 
                       totalProduction +
                       GDPperCapita + 
                       totalProduction + 
                       totalGHG + HDI2015, 
                     data = ecoDataReg)

summary(binomialModel)
```

Our binomial hierarchical model largely agrees with our normal hierarchical model, though its exact numbers differ. We see that continent has a variance of 0.0745, which is larger than that of our normal model, but it's still quite small. This, again, suggests that adding continent to our model is not the most useful. We also seem to have two significant predictors this time: `GDPperCapita` and `HDI2015`. One hypothesis is that `GDPperCapita` and `HDI2015` may possibly be collinear. The Human Development Index essentially measures whether a country is a first, second, or third world country. Perhaps countries with higher GDP have higher HDI. 

# Visualizations
To visualize the random effect of continent, we produced two chloropleth maps of the world, where countries are colored by their respective net footprint. In the first chloropleth, we've filled in countries on a continuous scale, which is the case when our $y$ is the transformed net footprint distributed normally. In the second chloropleth, we've filled in countries on a discrete scale, which is the case when our binomially distributed $y$ is the categorical indicator of either ecological deficit or surplus. 

Below is the first chloropleth: 

```{r}
ggplot() + 
  geom_polygon(data = ecoData, 
               aes(x = long, y = lat, fill = transFootprint, group = group),
               col = "white") +
  scale_fill_continuous(low = "#dedaea", high = "#ec3093", 
                        guide = "colorbar", na.value = "white", 
                        name = "Net Ecological Footprint  ") +
  labs(title = "World Map of Transformed Net Footprint", x = "", y = "") +
  theme(legend.position = "bottom")
```

If you're confused what this map tells us, unfortunately we're in the same boat. We don't see any distinct countries that immediately flag our attention. In fact, most countries seem to hover between 2 and 3.5 on our net ecological footprint scale. There also don't seem to be significant differences between continents. But this is not so surprising since this is consistent with our models. 

Below is the second chloropleth: 

```{r}
ggplot() + 
  geom_polygon(data = ecoData, 
               aes(x = long, y = lat, fill = as.factor(binomFootprint), 
                   group = group),
               col = "white") +
  scale_fill_brewer(palette = "Accent", name = "Net Ecological Footprint", 
                    labels = c("Deficit", "Surplus")) +
  labs(title = "World Map of Ecological Deficit/Surplus", x = "", y = "") + 
  theme(legend.position = "bottom") 
```

Upon first glance, this map is much easier to read than our first chloropleth as we've replaced our continuous scale with a discrete one. South America seems to run a clear net ecological surplus. Perhaps this is not so surprising as South America is home to lots of wildlife, as well as the great Amazon rainforest. For other continents, however, there does not seem to be a clear winner between ecological footprint. The inconclusive results our second chloropleth map are also consistent with the findings in our models. 

# Conclusion
While our models were unsuccessful in detecting significant relationships between net footprint and our predictor variables (loosely)

try other predictors 
random effect of continent not necessary
viz confirms our models
tie back to food waste and ecosystem
